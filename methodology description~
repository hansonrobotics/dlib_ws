We have a set of data points in dlib (68 pairs of x and y points) for each frames (that probably appear 25 or more times per second) and their corresponding shapekeys/blendvalues values. In the datasets prepared there are rows that neutral values (zero values) for the shapekeys. For instance, in the dataset of points that are relevant for the brow up prediction there were target values with the browsup shape key being zero and also points that range between 0 and 1. 
Coming to the real time prediction of mimicking, factors such as the resolution, the distance of the face from the camera are considered. In our case a resolution of 256 x 256 is used during training dataset recording. Thus, the real time frames of 640 x 480 are also changed back to the former resolution.

Another point that needs to be considered is the difference of face size/distance of camera. In order to understand the difference and normalize back points, found that considering static points is important. The points that are relatively static while facial expressions change are the starting and end of points of the horizontal face(point x0 and x16). At least to some extend these two points seems to stay unchanged; a fact which helped factorizing the face size (or distance from camera) difference between the model's and the realtime ones. 
So when a set of realtime points come, they are first converted to the same resolution. Then by taking the first point in a neutral row from the model and then set it as the first point of the realtime point. The next points of the realtime are mapped by multiplying the difference between point i and i-1 by the factor calculated (a factor of x16 and x0 between the model's and realtime's) and adding it to the previous point already set. Doing so for all n points maps the realtime set to a kind of set that is similar to the ones used in the model (to some extend).
 

