#include <ros/ros.h>
#include <image_transport/image_transport.h>
#include <cv_bridge/cv_bridge.h>
#include <sensor_msgs/image_encodings.h>
#include <opencv2/objdetect/objdetect.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <std_msgs/String.h>
#include <math.h>
#include <dlib/opencv.h>
#include <dlib/image_processing/frontal_face_detector.h>
#include <dlib/image_processing/render_face_detections.h>
#include <dlib/image_processing.h>
#include <dlib/gui_widgets.h>
#include <unistd.h>
#include <vector>

using namespace std;
using namespace cv;
using namespace dlib;


double lmPoints[68][2];

double max_valueaR = 0;
double max_valueaL = 0;

bool publish = false;

double bvaR = 0;
double roundOff_bvaR = 0.000;

double bvaL = 0;
double roundOff_bvaL = 0.000;

dlib::image_window win;
dlib::frontal_face_detector detector;
dlib::shape_predictor pose_model;
ros::Publisher pub;

void dlibCallback(const sensor_msgs::ImageConstPtr& msg) {

    // Declare a variable to hold converted image(from ros to opencv)
    cv_bridge::CvImagePtr cvPtr;
    try {
        // Convert ros image into opencv matrix image
        cvPtr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
    } catch (cv_bridge::Exception& e) {
        ROS_ERROR("cv_bridge exception: %s", e.what());
        return;
    }

    // Declare a variable to hold an image frame and grab a frame
    cv::Mat temp;
    temp = cvPtr->image;

    // Turn OpenCV's Mat image into something dlib can deal with
    dlib::cv_image<dlib::bgr_pixel> cimg(temp);

    // Detect faces 
    std::vector<dlib::rectangle> faces = detector(cimg);

    // Find the pose of each face.
    std::vector<dlib::full_object_detection> shapes;

    for (unsigned long i = 0; i < faces.size(); ++i)
        shapes.push_back(pose_model(cimg, faces[i]));

    // Display it all on the screen
    win.clear_overlay();
    win.set_image(cimg);
//    win.add_overlay(render_face_detections(shapes));

    //Declare variables to process and store messages to be published
    std_msgs::String smsg;
    std::stringstream ss;

    //Enters if any shape detected has dlib drawn overlays
    if(shapes.size()>0){

        for (unsigned long i = 0; i < shapes.size(); ++i) // Iterate through shapes
        {                    
            const full_object_detection& d = shapes[i]; // Hold the detected face i
            for (unsigned long i = 0; i < 68; ++i) // Hold all the 68 face landmark coordinates(x, y)
            {
                lmPoints[i][0] = (double)d.part(i).x();
                lmPoints[i][1] = (double)d.part(i).y();
            }
        }

        // Do something for publishing

        publish = true;
        if (publish) 
        {
            // Publish- shapekeyname:shapekeyvalue;shapekeyname:shapekeyvalue... etc
            publish = false;
            const char* const list[] = {"browCenterUP", "browCenterDN", "browInnerUPL",  "browInnerDNL", "browInnerUPR", "browInnerDNR", 
                                         "browOuterUPL", "browOuterDNL", "browOuterupR", "browOuterDNR", "winceL", "winceR",
                                         "sneerL", "sneerR", "eyesLookdn", "eyeslookup", "eyeFlareUPL", "eyeBlinkUPL",
                                         "eyeFlareUPR", "eyeBlinkUPR", "eyeBlinkLOL", "eyeFlareLOL", "eyeBlinkLOR", "eyeFlareLOR",
                                         "lipUPCUP", "lipUPCDN", "lipUPLUP", "lipUPLDN", "lipUPRUP", "lipUPRDN",
                                         "lipsSmileL", "lipsSmileR", "lipsWideL", "lipsNarrowL", "lipsWideR", "lipsNarrowR",
                                         "lipDNCDN", "lipDNCUP", "lipDNLDN", "lipDNLUP", "lipDNRDN", "lipDNRUP",
                                         "lipsFrownL", "lipsFrownR", "lipJAWDN"
            };

            const size_t len = sizeof(list) / sizeof(list[0]);
            double r;
    
            // Format the string to be published on "/dlib_values"
            for (size_t i = 0; i < len; ++i)
            {
                roundOff_bvaL = 0.9;
                roundOff_bvaR = 0.9;
                if (list[i] == "lipsWideR")
                {                    
                    ss<<list[i]<<":"<<roundOff_bvaL;
                }else if (list[i] == "lipsWideL"){
                    ss<<list[i]<<":"<<roundOff_bvaR;
                }else{
                    ss<<list[i]<<":"<<0.0;
                }
                if (i < len-1)
                {
                    ss<<";"; // size-1 to remove the last "semicolon(;)"
                }
            }
            std::cout<<"\n########  List:  ########\n"<<ss.str()<<endl;
            smsg.data = ss.str();
            pub.publish(smsg);
        }
    } 
    else{
        cout<<"\nDlib-INFO: No Face Detected!"<<endl;
    }
}

int main(int argc, char **argv) {
//    char *homedir = getenv("HOME");
//    if (homedir != NULL) {
//            std::cout<<"Home directory is:"<<endl;
//            std::cout<<homedir<<endl;
//    }
//    else{
//        std::cout<<"Unable to locate home directory... \nplease hardset hompe directory..."<<endl;
//    }
    detector = dlib::get_frontal_face_detector();
    dlib::deserialize("/home/esku/catkin_ws/src/dlib_puppeteering/src/shape_predictor_68_face_landmarks.dat") >> pose_model;
    ros::init(argc, argv, "dlib_puppeteering_node");
    ros::NodeHandle nh;
    pub = nh.advertise<std_msgs::String>("/dlib_values", 1000);
    ros::Subscriber sub = nh.subscribe("/usb_cam_node/image_raw", 1, dlibCallback);
    ros::spin();
}
